{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BRFSS Playground - HBR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heiarchical Bayesian Regression to Predict Mental Health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import halfcauchy\n",
    "from sklearn.metrics import f1_score\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "brfss_norm = pd.read_csv('../data/brfss_normed.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96986, 63)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brfss_norm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "drop_vars = ['B_ID', 'SMP_WGHT', 'MNTL_HLTH_LEV_BRFSS', 'MENTAL_HEALTH_30_BRFSS']\n",
    "brfss_vars = [\n",
    "    c for c in brfss_norm.columns.values if c not in drop_vars\n",
    "]\n",
    "X = brfss_norm[brfss_vars].copy()\n",
    "y = brfss_norm['MNTL_HLTH_LEV_BRFSS'].copy()\n",
    "y_simple = y.copy()\n",
    "y_simple.loc[y_simple > 0] = 1\n",
    "y_simple.loc[y_simple == 0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split training/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "behaviors = [\n",
    "    'ROUTINE_CHECK_BRFSS',\n",
    "    'INTERNET_USE_BRFSS',\n",
    "    'SMK_NOW_BRFSS',\n",
    "    'TRY_QUIT_SMK_BRFSS',\n",
    "    'SNUFF_BRFSS',\n",
    "    'CNSM_FT_DAY_BRFSS',\n",
    "    'PA_CAT_BRFSS',\n",
    "    'AER_STRNGH_GUIDE_BRFSS',\n",
    "    'PHYS_HLTH_LEV_BRFSS',\n",
    "    'HVY_DRNKR_BRFSS',\n",
    "    'AVG_NUM_DRNK_30_BRFSS',\n",
    "    'BINGE_DRNK_30_BRFSS',\n",
    "    'DRNK_PER_DAY_BRFSS',\n",
    "    'DLY_FF_SERVE_BRFSS',\n",
    "    'DLY_FT_SERVE_BRFSS',\n",
    "    'DLY_FJ_SERVE_BRFSS',\n",
    "    'DLY_GRN_VEG_SERVE_BRFSS',\n",
    "    'LARGE_NUM_DRNK_30_BRFSS',\n",
    "    'MET_VAL_BRFSS',\n",
    "    'MET_VAL_OTHR_BRFSS',\n",
    "    'TTL_MIN_OF_PA_WEEK_BRFSS',\n",
    "    'TTL_MIN_OF_VIG_WEEK_BRFSS',\n",
    "    'MIN_OF_PA_WEEK_BRFSS',\n",
    "    'MIN_OF_PA_WEEK_OTHR_BRFSS',\n",
    "    'MIN_OF_VIG_WEEK_BRFSS',\n",
    "    'MIN_OF_VIG_WEEK_OTHR_BRFSS',\n",
    "    'DLY_POTATO_SERVE_BRFSS',\n",
    "    'DLY_OTHR_VEG_SERVE_BRFSS',\n",
    "    'NUM_DRNKS_PER_WEEK_BRFSS',\n",
    "    'TOTAL_FT_DAY_BRFSS',\n",
    "    'MIN_OF_EX_WEEK_BRFSS',\n",
    "    'MIN_OF_EX_WEEK_OTHR_BRFSS',\n",
    "    'TOTAL_VEG_DAY_BRFSS'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_weights(mu_weights, std_weights):\n",
    "    \"\"\"\n",
    "    Sample a set of logistic regression weights for each person\n",
    "    \n",
    "    :param mu_weights: np.array<float>, num_clusters x num_weights matrix \n",
    "                       representing the mean of the distribution of the weights\n",
    "    :param std_weights: np.array<float>, num_clusters x num_weights vector \n",
    "                       representing the std of the distribution of the weights\n",
    "                       \n",
    "    :return sampled_weights: np.array<float>, num_clusters x num_weights matrix\n",
    "                             represents the sample weight for each cluster\n",
    "    \"\"\"\n",
    "    # Setup matrices\n",
    "    sampled_weights = np.zeros(shape=(mu_weights.shape[0], mu_weights.shape[1]))\n",
    "    \n",
    "    # Sample the weights\n",
    "    for i in range(sampled_weights.shape[0]):\n",
    "        for j in range(sampled_weights.shape[1]):\n",
    "            # Sample the weight\n",
    "            sampled_weights[i, j] = np.random.normal(loc=mu_weights[i, j], scale=std_weights[i, j])\n",
    "            \n",
    "    return sampled_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Calculate the sigmoid function.\n",
    "    \n",
    "    :param x: np.ndarray<float>, 1 x n vector of values\n",
    "    \n",
    "    :return: 1 / (1 + exp(-x))\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-1 * x))\n",
    "    \n",
    "def calculate_result(weights, cluster_matrix, training_data, thresh):\n",
    "    \"\"\"\n",
    "    Calculate the logistic regression value given a weights matrix and set of stats.\n",
    "    \n",
    "    :param weights: np.array<float>, num_clusters x num_weights matrix\n",
    "                    the logistic regression weights for each cluster\n",
    "    :param cluster_matrix: np.array<float>, num_people x num_clusters matrix\n",
    "                    the matrix showing how much each individual (task) is within each cluster\n",
    "    :param training_data: np.array<float>, num_people x num_variables matrix\n",
    "                    the training data\n",
    "    :param thresh: float, threshold for classfication\n",
    "    \"\"\"\n",
    "    # Go through the training data, and get a calculation for each cluster\n",
    "    y_prob = np.zeros(shape=(cluster_matrix.shape[0], 1))\n",
    "    \n",
    "    for i in range(training_data.shape[0]):\n",
    "        # First get results per cluster\n",
    "        person_result = np.sum(weights * np.transpose(training_data[i, :]), axis=1)\n",
    "        # Send the vector through a sigmoid function\n",
    "        person_result = sigmoid(person_result)\n",
    "        # Now multiply by weight\n",
    "        person_result = np.sum(cluster_matrix[i] * person_result)\n",
    "        # Store\n",
    "        y_prob[i] = person_result\n",
    "        \n",
    "    y_prob[y_prob > thresh] = 1\n",
    "    y_prob[y_prob <= thresh] = 0\n",
    "    \n",
    "    return y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hblr(X_train, y_train, thresh, cluster_matrix, mu_weights, std_weights):\n",
    "    \"\"\"\n",
    "    Solve the HBLR regression\n",
    "    \n",
    "    :param X_train: np.array<float>, n_people x n_params, the training data\n",
    "    :param y_train: np.array<float>, n_people x 1, the training objective\n",
    "    :pram thresh: <float>, threshold for classification\n",
    "    :param cluster_matrix: np.array<float>, num_people x num_clusters matrix\n",
    "                    the matrix showing how much each individual (task) is within each cluster\n",
    "   \n",
    "    :param mu_weights: np.array<float>, num_clusters x num_weights matrix \n",
    "                       representing the mean of the distribution of the weights\n",
    "    :param std_weights: np.array<float>, num_clusters x num_weights vector \n",
    "                       representing the std of the distribution of the weights\n",
    "                       \n",
    "    :return f1_score: <float> The f1_score of the current model\n",
    "    \"\"\"\n",
    "    \n",
    "    # First get weights\n",
    "    weights = sample_weights(mu_weights, std_weights)\n",
    "    \n",
    "    # Then run prediction\n",
    "    y_pred = calculate_result(weights, cluster_matrix, X_train, thresh)\n",
    "    \n",
    "    # Return F1\n",
    "    print(y_pred.shape)\n",
    "    return -1 * f1_score(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mu_normal_mu = np.array(\n",
    "    [[0, 0], [0, 0]]\n",
    ")\n",
    "\n",
    "test_mu_normal_std = np.array(\n",
    "    [[1, 1], [1, 1]]\n",
    ")\n",
    "\n",
    "test_std_cauchy_scale = np.array(\n",
    "    [[1, 1], [1, 1]]\n",
    ")\n",
    "\n",
    "test_weights = sample_weights(test_mu_normal_mu, test_mu_normal_std, test_std_cauchy_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_weights = np.array([\n",
    "    [0.3, 0.5, 0.1],\n",
    "    [0.2, 0.8, 0.05],\n",
    "    [0.1, 0.4, 0.6]\n",
    "])\n",
    "\n",
    "test_training_data = np.array([\n",
    "    [1, 2, 3],\n",
    "    [1, 4, 5]\n",
    "])\n",
    "\n",
    "test_cluster_matrix = np.array([\n",
    "    [0.1, 0.4, 0.5],\n",
    "    [0.3, 0.6, 0.1]\n",
    "])\n",
    "\n",
    "test_thresh = 0.4\n",
    "\n",
    "calculate_result(test_weights, test_cluster_matrix, test_training_data, test_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_samp = X.sample(n=5000, random_state=42)\n",
    "X_samp = pd.concat([pd.DataFrame(data=np.ones(shape=(X_samp.shape[0], 1)), index=X_samp.index), X_samp], axis=1)\n",
    "y_samp = y.loc[X_samp.index]\n",
    "y_samp[y_samp > 0] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 5\n",
    "thresh_0 = 0.7\n",
    "cluster_matrix_0 = np.ones(shape=(X_samp.shape[0], n_clusters)) * (1.0 / n_clusters)\n",
    "mu_weights_0 = np.zeros(shape=(n_clusters, X_samp.shape[1]))\n",
    "std_weights_0 = np.ones(shape=(n_clusters, X_samp.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daadler0309/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.10499227997941328"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hblr(X_samp.as_matrix(), y_samp.as_matrix(), thresh_0, cluster_matrix_0, mu_weights_0, std_weights_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "minimize(\n",
    "    fun=hblr,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
